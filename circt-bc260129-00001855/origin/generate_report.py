#!/usr/bin/env python3
import json
from datetime import datetime

# åŠ è½½æ•°æ®
with open('analysis.json', 'r') as f:
    analysis = json.load(f)

with open('duplicates.json', 'r') as f:
    duplicates = json.load(f)

# ç”ŸæˆMarkdownæŠ¥å‘Š
report_md = f"""# CIRCT Bug é‡å¤æ£€æŸ¥æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**åˆ†æžID**: {duplicates['bug_id']}

---

## ðŸ“‹ Bug æ‘˜è¦

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **Dialect** | {duplicates['bug_summary']['dialect']} |
| **å·¥å…·** | {duplicates['bug_summary']['tool']} |
| **Pass** | {duplicates['bug_summary']['pass']} |
| **é”™è¯¯ä¿¡æ¯** | `{duplicates['bug_summary']['error_message']}` |
| **å…³é”®è¯** | {', '.join([f'`{kw}`' for kw in duplicates['bug_summary']['keywords']])} |

---

## ðŸ” æœç´¢ç­–ç•¥

### ä½¿ç”¨çš„æŸ¥è¯¢

"""

# æ·»åŠ æœç´¢æŸ¥è¯¢
for i, query in enumerate(analysis.get('keywords', []), 1):
    report_md += f"- Query {i}: `{query}`\n"

report_md += f"""
### æœç´¢ç»“æžœç»Ÿè®¡

- **æ€»æŸ¥è¯¢æ•°**: {duplicates['search_summary']['queries_used']}
- **æ‰¾åˆ°çš„Issues**: {duplicates['search_summary']['total_issues_found']}
- **åˆ†æžçš„Issues**: {duplicates['search_summary']['issues_analyzed']}

---

## ðŸŽ¯ é‡å¤æ£€æŸ¥ç»“æžœ

### ðŸš¨ å»ºè®®: **{duplicates['recommendation'].upper()}**

**åŽŸå› **: {duplicates.get('recommendation_reason', 'æ— ')}

### åŒ¹é…è¯„åˆ†

| Issue # | ç›¸ä¼¼åº¦ | æ ‡é¢˜ | çŠ¶æ€ |
|---------|--------|------|------|
"""

# æ·»åŠ è¯¦ç»†çš„Issueè¡¨æ ¼
for item in duplicates['duplicate_check_results']:
    issue_num = item['issue_number']
    score = item['similarity_score']
    title = item['title'][:60] + '...' if len(item['title']) > 60 else item['title']
    state = item['state']
    report_md += f"| #{issue_num} | {score}% | {title} | {state} |\n"

report_md += f"""

---

## ðŸ“Š è¯¦ç»†åˆ†æžç»“æžœ

### æœ€ç›¸ä¼¼çš„Issue: #{duplicates['most_similar_issue']}

**ç›¸ä¼¼åº¦**: {duplicates['highest_similarity_score']}%

"""

# æ·»åŠ æœ€ç›¸ä¼¼Issueçš„è¯¦ç»†ä¿¡æ¯
if duplicates['duplicate_check_results']:
    top_issue = duplicates['duplicate_check_results'][0]
    report_md += f"""
**æ ‡é¢˜**: {top_issue['title']}

**URL**: [{top_issue['url']}]({top_issue['url']})

**çŠ¶æ€**: {top_issue['state']}

#### ç›¸ä¼¼åº¦è¯„åˆ†è¯¦è§£

"""
    for key, value in top_issue['detail_scores'].items():
        report_md += f"- **{key}**: {value:.1f}%\n"
    
    report_md += f"""
#### åŒ¹é…è¯¦æƒ…

- **åŒ¹é…çš„å…³é”®è¯**: {', '.join([f'`{kw}`' for kw in top_issue['match_details']['keywords_found']]) or 'æ— '}
- **é”™è¯¯ä¿¡æ¯åŒ¹é…**: {'âœ… æ˜¯' if top_issue['match_details']['has_error_message'] else 'âŒ å¦'}
- **å·¥å…·åŒ¹é…**: {'âœ… æ˜¯' if top_issue['match_details']['has_tool'] else 'âŒ å¦'}
- **DialectåŒ¹é…**: {'âœ… æ˜¯' if top_issue['match_details']['has_dialect'] else 'âŒ å¦'}
- **PassåŒ¹é…**: {'âœ… æ˜¯' if top_issue['match_details']['has_pass'] else 'âŒ å¦'}

---

### æ‰€æœ‰åŒ¹é…çš„Issues

"""
    
    for i, issue in enumerate(duplicates['duplicate_check_results'], 1):
        report_md += f"""
#### {i}. Issue #{issue['issue_number']} - ç›¸ä¼¼åº¦ {issue['similarity_score']}%

**æ ‡é¢˜**: {issue['title']}

**é“¾æŽ¥**: {issue['url']}

**çŠ¶æ€**: {issue['state']}

**åŒ¹é…çš„å…³é”®è¯**:
"""
        if issue['match_details']['keywords_found']:
            for kw in issue['match_details']['keywords_found']:
                report_md += f"- `{kw}`\n"
        else:
            report_md += "- æ— \n"

report_md += """
---

## ðŸ’¡ å»ºè®®

"""

if duplicates['recommendation'] == 'likely_duplicate':
    report_md += f"""### âš ï¸ å¯èƒ½æ˜¯é‡å¤æŠ¥å‘Š

æ­¤Bugä¸Ž Issue #{duplicates['most_similar_issue']} é«˜åº¦ç›¸ä¼¼ (ç›¸ä¼¼åº¦ {duplicates['highest_similarity_score']}%)ã€‚

**å»ºè®®æ“ä½œ**:
1. å®¡æŸ¥ Issue #{duplicates['most_similar_issue']} çš„å†…å®¹
2. å¦‚æžœç¡®è®¤æ˜¯åŒä¸€é—®é¢˜ï¼Œå¯ä»¥å…³é—­æ­¤Bugæˆ–æ·»åŠ å‚è€ƒé“¾æŽ¥
3. å¦‚æžœæ˜¯ä¸åŒçš„é—®é¢˜ï¼Œè¯·æ›´æ–°Issueæè¿°ä»¥æ˜Žç¡®å·®å¼‚

**å‚è€ƒé“¾æŽ¥**: https://github.com/llvm/circt/issues/{duplicates['most_similar_issue']}
"""

elif duplicates['recommendation'] == 'review_existing':
    report_md += f"""### ðŸ” éœ€è¦äººå·¥å®¡æŸ¥

æ­¤Bugä¸Žå·²æœ‰Issuesæœ‰ä¸€å®šå…³è”æ€§ï¼Œä½†ç›¸ä¼¼åº¦å¤„äºŽä¸­ç­‰æ°´å¹³ (æœ€é«˜ç›¸ä¼¼åº¦ {duplicates['highest_similarity_score']}%)ã€‚

**å»ºè®®æ“ä½œ**:
1. ä»”ç»†å®¡æŸ¥æœ€ç›¸ä¼¼çš„Issue: #{duplicates['most_similar_issue']}
2. æ¯”è¾ƒä¸¤ä¸ªIssuesçš„å…·ä½“ç»†èŠ‚å’Œå¤çŽ°æ­¥éª¤
3. æ ¹æ®å·®å¼‚å†³å®šæ˜¯å¦ä¸ºé‡å¤æˆ–ç›¸å…³é—®é¢˜
4. å¦‚æžœç›¸å…³ä½†ä¸å®Œå…¨ç›¸åŒï¼Œå¯ä»¥æ·»åŠ äº¤å‰å¼•ç”¨
"""

else:
    report_md += f"""### âœ… å»ºè®®ä½œä¸ºæ–°Issue

æœªæ‰¾åˆ°æ˜Žæ˜¾ç›¸å…³çš„çŽ°æœ‰Issue (æœ€é«˜ç›¸ä¼¼åº¦ä»… {duplicates['highest_similarity_score']}%)ã€‚

**å»ºè®®æ“ä½œ**:
1. æ­¤Bugåº”è¯¥ä½œä¸ºæ–°Issueæäº¤åˆ° llvm/circt
2. ç¡®ä¿æä¾›æ¸…æ™°çš„æè¿°ã€å¤çŽ°æ­¥éª¤å’Œå †æ ˆè·Ÿè¸ª
3. ä½¿ç”¨å»ºè®®çš„å…³é”®è¯æ ‡è®°Issue
4. æä¾›æœ€å°åŒ–çš„æµ‹è¯•ç”¨ä¾‹
"""

report_md += f"""

---

## ðŸ“ˆ æœç´¢æŸ¥è¯¢æ€»ç»“

ä½¿ç”¨çš„æœç´¢æŸ¥è¯¢:

"""

# ä»Žsearch_resultsèŽ·å–æŸ¥è¯¢åˆ—è¡¨ (å¦‚æžœå¯ç”¨)
try:
    with open('search_results.json', 'r') as f:
        search_results = json.load(f)
    for query in search_results['search_queries']:
        report_md += f"- `{query}`\n"
except:
    pass

report_md += f"""

---

## ðŸ”§ æŠ€æœ¯ç»†èŠ‚

### Bug ç‰¹å¾

**Pass**: {analysis.get('pass_name', 'æœªçŸ¥')}

**Dialect**: {analysis.get('dialect', 'æœªçŸ¥')}

**å·¥å…·**: {analysis.get('tool', 'æœªçŸ¥')}

**é”™è¯¯ç±»åž‹**: {analysis.get('crash_type', 'æœªçŸ¥')}

**å…³é”®è¯**:
"""

for kw in analysis.get('keywords', []):
    report_md += f"- `{kw}`\n"

report_md += f"""

### æ ¹æœ¬åŽŸå› 

{analysis.get('root_cause', {}).get('description', 'æœªçŸ¥')}

**ç¼ºå¤±çš„å¤„ç†å™¨**: {analysis.get('root_cause', {}).get('missing_handler', 'æœªçŸ¥')}

**ä¸æ”¯æŒçš„ç±»åž‹**: {analysis.get('root_cause', {}).get('unsupported_type', 'æœªçŸ¥')}

### è§¦å‘æž„é€ 

**ç±»åž‹**: {analysis.get('trigger_construct', {}).get('type', 'æœªçŸ¥')}

**SystemVerilog**: `{analysis.get('trigger_construct', {}).get('systemverilog', 'æœªçŸ¥')}`

**IRç±»åž‹**: `{analysis.get('trigger_construct', {}).get('ir_type', 'æœªçŸ¥')}`

---

## ðŸ“ æ³¨æ„äº‹é¡¹

- ç›¸ä¼¼åº¦åˆ†æ•°åŸºäºŽå…³é”®è¯åŒ¹é… (40%)ã€é”™è¯¯ä¿¡æ¯åŒ¹é… (30%)ã€å·¥å…·/DialectåŒ¹é… (20%) å’ŒPassåŒ¹é… (10%)
- æœç´¢ç»“æžœåŸºäºŽGitHub Issues APIçš„å¯ç”¨æ•°æ®
- å»ºè®®å§‹ç»ˆè¿›è¡Œäººå·¥å®¡æŸ¥ä»¥ç¡®è®¤é‡å¤å…³ç³»
- å¦‚æžœIssueå·²åœ¨llvm/circtä¸­å­˜åœ¨ï¼Œå¯ä»¥æ·»åŠ +1ååº”æˆ–æ–°å¢žä¿¡æ¯

---

**ç”Ÿæˆè€…**: CIRCT Bug é‡å¤æ£€æŸ¥ç³»ç»Ÿ  
**ç‰ˆæœ¬**: 1.0  
**æœ€åŽæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

# ä¿å­˜æŠ¥å‘Š
with open('duplicates.md', 'w') as f:
    f.write(report_md)

print("âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ")
print(f"\nðŸ“„ æ–‡ä»¶: duplicates.md")
print(f"ðŸ“ å¤§å°: {len(report_md)} å­—ç¬¦")
print("\n" + "="*60)
print(report_md[:1000] + "\n..." if len(report_md) > 1000 else report_md)

